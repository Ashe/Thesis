\documentclass[11pt, a4paper]{article}
\usepackage[left=40mm, right=20mm, top=20mm, bottom=20mm, includefoot]{geometry}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{ulem} 
\usepackage[english]{babel}
\usepackage[autostyle]{csquotes}
\usepackage{listings}
\usepackage[style=apa,backend=biber, language=english]{biblatex}
\usepackage{url}
\addbibresource{sources.bib}
\setlength{\parindent}{0ex}
\setlength{\parskip}{1.5ex}
\font\titlefont=cmr10 at 18pt
\MakeOuterQuote{"}

\lstset{
  frame=tb, % draw a frame at the top and bottom of the code block
  tabsize=4, % tab space width
  showstringspaces=false, % don't mark spaces in strings
  numbers=left, % display line numbers on the left
  commentstyle=\color{green}, % comment color
  keywordstyle=\color{blue}, % keyword color
  stringstyle=\color{red} % string color
}

\linespread{1.5}
\begin{document}

\title{\titlefont The path to the right decision: An investigation into using heuristic pathfinding algorithms for decision making}
\author{Ashley Smith}
\date{\today}
\maketitle
\thispagestyle{empty}

\renewcommand\abstractname{\textbf{Abstract}}
\begin{abstract}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras justo velit, vestibulum sit amet turpis in, interdum rhoncus magna. Proin pulvinar posuere iaculis. Duis vulputate tristique arcu, id pretium ante blandit ut. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Nam augue tellus, mattis quis consequat id, facilisis eu lectus. Vivamus euismod non quam sed condimentum. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Phasellus vitae consequat nisi. Morbi vulputate tellus ut nibh vulputate, vitae blandit ex faucibus.
\end{abstract}

\cleardoublepage
\setcounter{page}{1}
\pagenumbering{roman}
\tableofcontents

\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{1}
\section{Introduction}

\subsubsection{Video games and artificial intelligence}

Games are good for the global economy. \citeauthor{Newzoo} reports that in October 2019 the global games market was worth \$148 billion with mobile games accounting for 46\% of that. In order to remain competetive, developers are pushed to make bigger, better and more complex games. The evolution of the technologies available has allowed for a greater number of elements to be simulated in the game world which could potentially increase a game's worth (\cite{blow2004game}). The entry barrier to creating these good looking and well executed games has been lifted with the establishment of engines like Unity (\cite{Unity}) and Unreal (\cite{Unreal}) to the point where even non-programmers can get involved using textual or visual scripting.

For many years, only the game's graphics were considered important (\cite{yap2002grid}; \cite{blow2004game}), however, good physics systems or competent AI (Artificial Intelligence) are now recognised as a way of improving the end-user's experience just as much well (\cite{blow2004game}). Game AI is different from the normal, academic AI as it simulates behaviour and aims to be believable and fun, whereas an academic AI aims to achieve a level of intelligence or autonomy to excel at a given task (\cite{nareyek2004ai}, p.60).

\subsubsection{The need for game AI}

AI has multiple uses within a games context but the majority of use cases employ AI to control the characters featured in a level of the game. \citeauthor{laird2001human} (\citeyear{laird2001human}, p.16) said that whether these characters are replacements for opposing players or characters that act as companions, villains and plot devices, "human-level AI can expand the types of experiences people have playing computer games". Using AI opens up the opportunity for increasing the difficulty of the game, and could be perceived as the kind of challenges that make games fun (\cite{buro2004call}, p.2). \citeauthor{laird2001human} (\citeyear{laird2001human}, p.16) also hypothesised that utilising such an AI is a good step towards the development of enjoyable and challenging gameplay, and potentially to "completely new genres" (\cite{laird2001human}, p.17). 

 "Customers value great AI" (\cite{nareyek2004ai}, p.60) and so it's important to choose a suitable approach that fulfills the expectations of the player thus the requirements of the game (\cite{millington2019ai}, p.19). Academic AI can be made using algorithms inspired by biology such as neural networks or genetic algorithms and trained through iteratation or with datasets. These approaches aren't used in game AI because of the high requirements to train the AI to interact with a specific game (\cite{nareyek2004ai}, p.64), moreover, it is easy to train the AI to play too strongly ruin the game (\cite{tozour2002evolution}, p.13). Instead, game AI developers embrace simpler, non-learning algorithms due to them being easier to understand, implement and debug (\cite{tozour2002evolution}, p.7).

 \subsubsection{Approaches to game AI development}

The most basic forms of AI used in games take the form of a series of if-then statements and are known as a 'production rule systems' (\cite{tozour2002evolution}). These statements are organised in a list and the AI uses the behaviour of the rules that evaluate to $true$. The result is a very basic AI that is not only limited to what actions it can take but also when it can take them. Similarly, decision trees combine the same if-then style with branching structures to create game AI (\cite{nareyek2004ai}, p.62), and the tree and subtrees are recursively traversed until a leaf node is found with the desired behaviour. This process is very easy to understand and implement (\cite{millington2019ai}, p.295), and the branching structure makes visualisation of the process more intuitive than the basic list used in a production rule system. Because of this, many consider decision trees to be one of, if not the simplest techiques to making AI (\cite{millington2019ai}, p.295; \cite{tozour2002evolution}, p.7).

FSMs, or Finite State Machines, are the most common approach to game AI (\cite{orkin2006three}, p.1; \cite{millington2019ai}, p309) due to being easy to understand and the efficacy of their output. FSMs consist of a directed graph where each node represents a state and the edges represent the transitions between them (\cite{tozour2002evolution}, p.6). A character can only be in one state at time and has no memory of any previous states (\cite{colledanchise2014performance}); each state represents an expected behaviour and determines what they do and the conditions to switch to a different state (\cite{diller2004behavior}, p.3). In the right environment, the impression of a well thought out FSM could compete with that a neural network, at a fraction of the time and resource costs, despite not always arriving at the optimal decisions (\cite{sweetser2002current}). However, each new behaviour requires the creation of a new state and the conditions of which this state integrates and transitions into other states, making expansion and maintainance cumbersome (\cite{sweetser2002current}, p.2; \cite{lim2010evolving}, p.3). There's no easy way to combine the tests inside of FSMs and selecting the conditions for a state transition is still very much a process that must be done by hand (\cite{millington2019ai}, p.313). 

The need for more flexibility in game AI has lead to the creation adaptation of modular algorithms such as behaviour trees (\cite{lim2010evolving}, p.1). Like decision trees, the recursive structure of a behaviour tree is simple to understand and implement while also being high level, allowing for more sophisticated AI to be created in a modular fashion through the use of subtrees and different node types (\cite{shoulson2011parameterizing}, p.144), each performs an action or check and then proceeds to succeed or fail (\cite{lim2010evolving}, p.4. It is these types that make the AI process at a higher level than standard decision trees, and when combined with leaf nodes that perform checks and actions to build trees, and then combined again to make trees containing subtrees, the simplicity and elegance of this technique certainly demonstrates why behaviour trees are getting attention (\cite{shoulson2011parameterizing}, p.144).

\subsubsection{The relationship of pathfinding and game AI}

One common requirement for game AI is for the characters to be able to traverse the areas of the game in a way which meets the player's expectations logically and efficiently - a task known as pathfinding. Regardless of what an AI decides to do, a pathfinding mechanic needs to be in place to allow the AI to navigate to where it needs to go, maneuvering around obstacles while still taking a sensible route (\cite{graham2003pathfinding}, p.60). For most games, the algorithm of choice is A* as it is the de-facto standard pathfinding algorithm (\cite{millington2019ai}, p.197; \cite{botea2004near}, p.2; \cite{nareyek2004ai}, p.64; \cite{leigh2007using}, p.73).

The A* algorithm analyses the game's map and generates a path from one location to another while minimising a $cost$ value - this value can represent anything but usually it represents the time or distance to travel along a given route (\cite{yap2002grid}, p.44). This means that the pathfinding algorithm itself doesn't decide where to go, only how to get there and the manner in which it does so. When asked to calculate a path, a pathfinding algorithm is provided a graph of nodes to determine which nodes can be reached from which (\cite{nareyek2004ai}, p.61). The algorithm isn't concerned with the what the data represents or in what form it is given, whether it is two-dimensional or three-dimensional, what the $cost$ is of travelling from one node to another, as long as it is equipped with the right functionality to digest this information (\cite{millington2019ai}, p.277; \cite{graham2003pathfinding}, p.60).

With the pathfinding process taking place after the decision has been made, the opportunity to involve the data gathered from pathfinding algorithm is missed. Often, the AI will decide to approach the nearest object, but obstacles in the way mean that the cost of navigating to the destination is greater than some alternative. While implementing the algorithm isn't difficult, ensuring the AI generates a path to the correct destination is difficult to do well (\cite{forbus2002qualitative}). Perhaps on the way to the destination, the character has to also navigate past traps or other hazards where it will need to decide whether to avoid or pass through - decisions that A* isn't fully equipped to deal with on it's own. If the AI wanted to factor in these hazards and real cost values, it would have to perform a more advanced check on where to travel too, maybe even using the pathfinding algorithm multiple times to definitely make sure that it wants to take the generated path, potentially ruining the game's performance.

Pathfinding algorithms are actually general purpose search algorithms applied to a spacial context (\cite{cui2011based}, p.125; \cite{orkin2003applying}, p.6; \cite{yap2002grid}, p.46); there is no such restriction that these algorithms should be restricted to pathfinding when in a games context. \citeauthor{millington2019ai} (\citeyear{millington2019ai}, p.197) said that "pathfinding can also be placed in the driving seat, making decisions about where to move as well as how to get there". With search algorithms having the flexibility of being able to traverse graphs of nodes representing any kind of data, it's no stretch to imagine the A* search algorithm being applied to a graph containing the same tests and actions found in decision and behaviour trees in order to generate a 'path' of actions rather than a path of spacial data (\cite{higgins2002generic}, p.114). This is paper aims to investigate and re-engineer A* to make decisions rather than paths in a game context.

\subsection{Literature Review (11-12 pages)}

\subsubsection{Dijkstra's algorithm: A graph and tree search algorithm}

A search algorithm is a recursive method designed to find a match for a piece of data within a collection such as an array, graph or tree (\cite{friedman1976algorithm}). A piece of data is provided and the search algorithm typically returns whether it is present and it's location. (\citeauthor{dijkstra1959note})'s algorithm (\citeyear{dijkstra1959note}) is a search algorithm that operates on trees and graphs (which are then interpreted as trees). The algorithm calculates the shortest difference from any node on the graph to any other node. If a destination is provided, the algorithm can be terminated early to avoid unnecessary computation. 

Dijkstra's algorithm works through the recursive summation and comparison of distance values (\cite{dijkstra1959note}, p.269) - for each neighbour, the current node's distance from the start is added to the length between the current node and its neighbour. If this tentative value is lower than the current distance value of the neigbour, it replaces it. When all the neighbours have been considered, the node with the lowest tentative value on the graph is selected and permanently 'visited' (\cite{dijkstra1959note}). This process is repeated until the destination has been visited, and thus a path and the distance from the start to the destination can be retrieved. The problem with Dijkstra's algorithm is that it always selects the node with the lowest tentative distance value, meaning that the algorithm has no notion of direction and is calculating the lowest distance to nodes that may not be relevant to getting to the destination (\cite{millington2019ai}, p.214).

\subsubsection{A* algorithm: A heuristic best-first search algorithm}

A* is an improvement of Dijkstra's algorithm in this regard (\cite{hart1968formal}, p.101) - while it doesn't stray far from how Dijkstra's algorithm works in the sense that it operates using a tentative distance value and it keeps track of the nodes that have and haven't been visited, it does extend the algorithm using what's known as a heuristic approach (\cite{cui2011based}, p.126). "Heuristics are criteria, methods or principles for deciding which among several alternative courses of action promises to be the most effective in order to achieve some goal" (\cite{pearl1984heuristics}, p.3). This means that in a pathfinding situation, a heuristic function could estimate the distance to the goal, by ignoring walls and measuring in a straight line, to direct the algorithm in the right direction and avoid evaluating routes that travel in the wrong direction to make the process more efficient (\cite{cui2011based}, p.127). Heuristics enable A* to perform a best-first search (\cite{yap2002grid}, p46), as the heuristic now has the power to select which node is the best one to evaluate and prioritises it over the others (\cite{russell2016artificial}, p.94). A good heuristic algorithm should explore nodes that have the most potential for leading to the goal node (\cite{korf1985depth}).

When identifying the next node to expand, A* will take this heuristic distance into account using the formula $f(n) = g(n) + h(n)$ (\cite{hart1968formal}, p.102; \cite{russell2016artificial}, p.95), where $g(n)$ is the real distance the algorithm has calculated from the start node to node $n$, $h(n)$ is the heuristic distance from the current node $n$ and the destination, and $f(n)$ is the combination of these two metrics forming an estimate of the distance from the start node to the destination if travelling through route $n$ (\cite{hart1968formal}; \cite{millington2019ai}; \cite{graham2003pathfinding}, p.64). 

This heuristic component of A* transforms it into a family of algorithms where applying a different heuristic selects a different algorithm (\cite{hart1968formal}, p.107), moreover, implementing A* and using a heuristic that returns a constant value for all nodes reverts A* back into Dijkstra's algorithm (\cite{lester2005pathfinding}, p.10; \cite{millington2019ai}, p.237). Conversely, implementing a well-designed heuristic method can be used to guarantee optimal solutions, and using a heuristic that is somewhere in-between can output results with varying degrees of accuracy in exchange for faster exection (\cite{millington2019ai}, p.219).  The implementation of a good heuristic can be difficult, as making the heuristic take more factors into account for accuracy has the drawback of making the algorithm less efficient overall with the heuristic being frequently used throughout the process.

On the other hand, \citeauthor{graham2003pathfinding} (\citeyear{graham2003pathfinding}, p.68) argue that one of the constraints of games the industry is the "over-reliance" on the A* pathfinding algorithm and describe the development of its many extensions as a way of avoiding the discovery of new techniques. The pathfinding process can require a lot of CPU resources, sometimes to the point of stalling the game, when applied to larger graphs (\cite{cui2011based}, p.127; \cite{stentz1996map}, p.110; \cite{graham2003pathfinding}, p.67). This indicates that the performance of A* can vary depending on various factors, and is why it is important to optimise A* by selecting an suitable storage mechanism for the graph and internal node storage as well as using a reasonable heuristic that balances efficiency and efficacy (\cite{millington2019ai}, p.228).

\subsubsection{Decision making with A* using GOAP}

\citeauthor{orkin2003applying} (\citeyear{orkin2003applying}, p.11) expressed that expectations of AI are growing with the release of every new game, and that "we need to look toward more structured, formalized solutions to creating scalable, maintainable and re-usable decision making systems". Game AI techniques used in most games do not contain the scalability \citeauthor{orkin2003applying} envisions (\cite{laird2001human}, p.17), however, \citeauthor{higgins2002generic} (\citeyear{higgins2002generic}, p.117) declares that a pathfinding engine can be created generically, especially if you use a templated language to give the code even more reusability. Implementing A* in this way would allow it to be used for both regular pathfinding and any other uses you can get out of it(\cite{higgins2002generic}, p.120). With A* being efficient and optimisable (\cite{millington2019ai}, p.215), reusing A* for game AI has the potential to bring the benefits it usually brings to pathfinding while being adaptable enough to scale up and meet expectations.

Orkin (\citeyear{orkin2006three}, p.1) worked on the development of the game AI for the game F.E.A.R (\cite{FEAR}). The approach used for this AI was called GOAP which stands for 'Goal Oriented Action Planning' and actually uses the A* algorithm as part of its decision making process and "allows characters to decide not only what to do, but how to do it" (\cite{orkin2003applying}, p.1). GOAP changes the data to be processed by A* from spacial data such as coordinates into character AI state data, such as what you'd find in FSMs. Therefore, the output of A* is no longer a sequence of movements but a sequence of actions also known as a plan (\cite{orkin2003applying}, p.2; \cite{tozour2002evolution}, p.6).

GOAP essentially takes the idea of having state machines to encapsulate behaviours and replaces the hand-programming the conditions and connections of state transitions with a pathfinding process with the aim being the decoupling of states and their transitions (\cite{orkin2003applying}, p.2). The pathfinding process uses each node to represent a state and the edges between each node as the actions that lead to those states (\cite{orkin2003applying}, p.7) When GOAP is used, a goal is given for the character to achieve which gives the AI some direction and what is returned is the sequence of actions that will satisfy the goal (\cite{orkin2003applying}, p.1). An action is a representation of one thing the character will do to change the world in some way, like opening a door or picking up a weapon (\cite{orkin2003applying}, p.2); some actions have preconditions that require the execution of another action prior to it (\cite{orkin2003applying}, p.5). A* will then find the sequence of actions, the plan, that satisfies the character's goal while minimising an arbitrary $cost$ value - \citeauthor{orkin2003applying} (\citeyear{orkin2003applying}, p.4 - p.5) suggests that this process creates interesting character AI that can adapt to change while also having a code structure that is reusable, maintainable and "elegant".

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/goap_figure_1.png}
  \caption{An example of GOAP (\cite{orkin2003applying}, p.3)}
  \label{fig:goap}
\end{figure}

A* being used in GOAP means that fundamental formula $f(n) = g(n) + h(n)$ needs to be implemented: the calculation of a node's $fitness$ to determine the $cost$ of the actions taken up to that point and a heuristic function to determine the $cost$ of getting to the goal from a given node (\cite{orkin2003applying}, p.7). \citeauthor{orkin2003applying} (\citeyear{orkin2003applying}, p.7) also shares that the heuristic in GOAP can be calculated as the summation of unmet conditions of the goal node, but this is rather unclear. Given the example in figure \ref{fig:goap}, "the goal is to kill an enemy" (\cite{orkin2003applying}, p.3) could be interpreted in various ways that all seem unsuitable. If the condition is that the enemy is dead, the heuristic would not change for any action other than the goal state, making it potentially wasteful like Dijkstra's algorithm (\cite{millington2019ai}, p.214). Alternatively, if the condition was that the weapon needed to be drawn and ready to fire, it implies either the algorithm has been ran previously to determine the requirements of killing an enemy, or that they were programmed by the programmer - how would the starting state know that the weapon needed to be reloaded before drawing it? While GOAP does seem elegant, the graph in figure \ref{fig:goap} doesn't have a sizeable number of nodes; using dijkstra's algorithm wouldn't incur much of a performance cost with a graph this size. \citeauthor{orkin2003applying} (\citeyear{orkin2003applying}) suggests that a regressive search by starting at the goal and pathing to the start makes sense, and in figure \ref{fig:goap}, it does, as only one action can attack and so it's clear that the decision making process boils down to the character attacking the enemy.

Another problem of GOAP is that the high-level nature of the approach may not allow for enough control of the game (\cite{stanciu2012implementing}, p.87) - while making abstractions of the world is necessary for AI to process the information (\cite{buro2004call}, p.2) and thinking on a higher level is beneficial for making more humanlike decisions, the precision of the actions taken by the AI is both low level and very noticeable if incorrect (\cite{graham2003pathfinding}, p.60). Figure \ref{fig:goap} shows a decision making process that decides what to do but not necessarily where to do it. When the action "Goto Point" in figure \ref{fig:goap} get executed, there's no indication of how the destinations are generated other than satisfying the preconditions for another action (for example, moving to an object to activate it) (\cite{orkin2003applying}, p.7). 

This isn't specific to GOAP as it applies to every AI approach where the generation of these locations isn't part of the AI. Is the character's AI deciding where to go, or just deciding that it has to go somewhere? In order for "Goto Cover" to act in a similar way to the "Goto Point" action, a goal or action precondition would either have to require the character to be out of line-of-sight, or be using one of the designated cover spots. The latter of these would require the designation of these cover spots and then A* would be employed to find which coverspot would be the quickest to navigate to. The former would require calculating the closest position that allows the escape of line-of-sight. Both of these would have their own problems, and wrapping the entire pathfinding process as a single action would mean that the information from the pathfinding request would not be used in the decision making at all. Without utilising the AI's ability to create an impression of thought, the information given to these actions could be poorly chosen and "may be perceived as a lack of intelligence by a human player" (\cite{graham2003pathfinding}, p.63). To circumvent this, multiple "Goto Point" actions would be needed so that the planning system can evaluate each point into the workflow, but this could introduce its own problems without a well-designed heuristic that can distinguish between the different locations.

\subsubsection{Perception and processing of the game world}

Every approach to designing game AI needs to find a way to digest information about the character's environment that is relevant to the decision making process, and selecting this information is just as important as the form it is delivered in (\cite{cui2011based}, p.126). All game AI solutions need the world to be re-interpreted to be better suited for both decision making (\cite{buro2004call}, p.2) and pathfinding (\cite{diller2004behavior}, p.3). Particular geometry of the map may need to be interpreted as vantage points, choke points or safe spots; particular formations of enemy units may need to be not only counted but also assessed for tactical strengths, whether engaging the units head-on is better than running away to a better location, and finally, the interpretation of time such as whether there is enough time to navigate to what would otherwise be a better location for fighting the enemy (\cite{buro2004call}).

The digestion of the world needs to be done for both performance and gameplay needs. A* can suffer from performance problems when used with a large or inefficient graph of nodes and many solutions have been discovered to prevent or reduce the impact on performance. One such solution is known as hierarchical pathfinding, where the game's map is simplified into chunks, (\cite{cui2011based}, p.126). By simplifying a group or grid of nodes into a single node that represents the whole group (like a quadtree), the pathfinding process can be applied to larger worlds as if they were actually smaller (\cite{botea2004near}). 

This works well for typical pathfinding, but applying this notion to something like GOAP would require a different approach. There are large amount of actions a character can take at any given moment (\cite{nareyek2004ai}, p.62) and so applying a search algorithm to such a large set of tasks will make the process a lot slower than traditional methods if left unchecked. Hierarchical pathfinding essentially creates more nodes to expand in the short term to reduce the total number of nodes expanded in the long term and gain a net increase in performance, and so in order to apply it to decision making like GOAP, nodes would have to be grouped by other metrics that aren't necessarily distance, such as 'attacking' actions and 'defending' actions. Splitting the world state gameplay elements like this can get complicated - what if a certain unit in a strategy game can attack from a longer range, would attacking the enemy from a distance be a defensive maneuver or an offensive one, and how easy is this to change on a per-unit basis (\cite{weber2011building}).

D* was also implemented for a large node count (\cite{stentz1996map}, p.110).



END

In this paper, the mechanisms of the A* search algorithm are examined and re-engineered, through the substitution of input and output types, to investigate the modularity and adaptability of an AI made in this way. The aim of using this approach is to bring decision-making and pathfinding closer together and therefore simplifying the overarching process of perceiving, deciding and interacting in the game world.



\subsection{Methods and Methodologies}

\section {Design, Development and Evaluation}

\section{Design (14-15 pages when combined with development)}

\subsection {Development (14-15 pages when combined with design)}

\subsection {Results and Evaluation (11-12 pages including critical review)}

\section {Conclusions}

\subsection {Conclusions and Critical Review}

\printbibliography
\end{document}
