\documentclass[10pt]{article}
\usepackage[left=40mm, right=20mm, top=20mm, bottom=20mm, includefoot]{geometry}
\usepackage{listings}
\usepackage[style=apa,backend=biber, language=english]{biblatex}
\usepackage{url}
\addbibresource{sources.bib}
\setlength{\parindent}{0ex}
\setlength{\parskip}{1.5ex}
\font\titlefont=cmr10 at 18pt

\lstset{
  frame=tb, % draw a frame at the top and bottom of the code block
  tabsize=4, % tab space width
  showstringspaces=false, % don't mark spaces in strings
  numbers=left, % display line numbers on the left
  commentstyle=\color{green}, % comment color
  keywordstyle=\color{blue}, % keyword color
  stringstyle=\color{red} % string color
}

\begin{document}

\title{\titlefont The path to the right decision: An investigation into using heuristic pathfinding algorithms for decision making}
\author{Ashley Smith}
\date{\today}
\maketitle

\renewcommand\abstractname{\textbf{Abstract}}
\begin{abstract}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras justo velit, vestibulum sit amet turpis in, interdum rhoncus magna. Proin pulvinar posuere iaculis. Duis vulputate tristique arcu, id pretium ante blandit ut. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Nam augue tellus, mattis quis consequat id, facilisis eu lectus. Vivamus euismod non quam sed condimentum. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Phasellus vitae consequat nisi. Morbi vulputate tellus ut nibh vulputate, vitae blandit ex faucibus.
\end{abstract}

\clearpage
\section{Introduction}

\subsubsection{Video games and artificial intelligence}

Games are good for the global economy. \citeauthor{Newzoo} reports that in October 2019 the global games market was worth \$148 billion with mobile games accounting for 46\% of that. In order to remain competetive in the growing and changing market, developers are pushed to make bigger, better and more complex games. Blow (\citeyear{blow2004game}) describes how the evolution of the technologies available allowed for a greater number of elements to be simulated in the game world at the same time, which in turn could increase a game's overall potential worth. Video games are just as much about their design as they are about their programming, and the entry barrier to creating good looking and well executed games has been lifted with the establishment of engines like Unity (\cite{Unity}) and Unreal (\cite{Unreal}) to the point where even non-programmers can get involved using textual or visual scripting.

For many years, making a good game has been about improving graphics to be higher quality and more realistic (\cite{yap2002grid}; \cite{blow2004game}). However, it is becoming clear that graphics aren't everything and that good physics systems or competent AI (Artificial Intelligence) can improve the end-user's experience just as much as graphics if not more (\cite{blow2004game}). When referring to AI in a games context, there is a significant difference between the approaches used to create academic AI and the AI used in games. The average game AI simulates a decision making process where the actions to be taken are as believable and fun as possible in the game's context whereas the objective of an academic AI is typically to achieve a level of intelligence or autonomy that enables the AI to optimally excel at a given task (\cite{nareyek2004ai}, p.60). It's not difficult to make a simply AI that always wins against the player, but player's wouldn't enjoy a game they couldn't win (\cite{tozour2002evolution}), and so the distinction between the objectives of these approaches is very important.

\subsubsection{The need for game AI}

AI has multiple uses within a games context but the majority of use cases employ AI to control the characters featured in a level of the game. \citeauthor{laird2001human} (\citeyear{laird2001human}, p.16) said that whether these characters are replacements for opposing players (nicknamed 'Bots') or used to create NPCs (Non Player Characters) to act as companions, villains and plot devices in a role-playing or narrative context, "human-level AI can expand the types of experiences people have playing computer games". Using AI opens up the opportunity for increasing the difficulty of the game, and, so long as the AI can be adapted to the player's strength, this difficulty will be perceived as the same kind of challenges that make games fun (\cite{buro2004call}, p.2). \citeauthor{laird2001human} (\citeyear{laird2001human}, p.16) also hypothesised that utilising such an AI is a good step towards the development of enjoyable and challenging gameplay, and potentially to "completely new genres" (\cite{laird2001human}, p.17). While "customers value great AI" (\cite{nareyek2004ai}, p.60), the fact that marketing material cannot advertise enjoyable game AI as easily as appealing graphics means that, in comparison to graphics or physics, AI rarely gets the same time or resource investment it needs to improve (\cite{nareyek2004ai}, p.60).

When developing game AI, it is very important to choose a suitable approach that fulfills the requirements of the game (\cite{millington2019ai}, p.19). Academic AI can be made using algorithms inspired by biology such as neural networks or genetic algorithms and trained through iteratation or with datasets. Genetic algorithms simulate natural selection and evolution using data to immitate gene crossover and mutation (\cite{tozour2002evolution}). Similarly, neural networks simulate neuron patterns in the brain to map inputs to outputs (\cite{tozour2002evolution}). These approaches aren't used in game AI due to the requirements necessary to train, tune and test the AI, moreover, the AI would need to be tailored to play a given game in order to take advantage of game specific requirements (\cite{nareyek2004ai}, p.64). Instead, game AI developers embrace simpler, non-learning algorithms due to them being easier to understand, implement and debug (\cite{tozour2002evolution}, p.7).

\subsubsection{AI development}

The most basic forms of AI used in games take the form of a series of if-then statements and are known as a 'production rule systems' (\cite{tozour2002evolution}). The AI is divided into two parts: the first being the ruleset that the AI has to follow and the second is the execution of the response to said rules. The result is a very basic AI that is not only limited to what actions it can take but also when it can take them. AI created in this way is perfectly suited to simple games with a small number of scenarios that the programmer can check for and respond to by hand. Additionally, games where there are a lot of agents needing to make decisions simultaneously would also benefit from a basic AI.

Decision trees are another way to create AI that have applications for games. Building on the same fundamentals as production rule systems, decision trees accept a series of inputs such as the game environment and ask questions in the same if-then style (\cite{tozour2002evolution}). Decision trees are branching structures containing nodes, where each node represents a test condition that leads either a sub-tree or a leaf, and the leaves are dead-end nodes that represent an action the AI should take (\cite{nareyek2004ai}, p.62). Traversal of a decision tree begins at the root node, where each conditional statement selects which child node to investigate next (\cite{nareyek2004ai}). This process repeats until a leaf node is reached containing the action the AI should take. This process is very easy to understand and implement (\cite{millington2019ai}, p.295), and the branching structure makes visualisation of the process more intuitive than the basic list used in a production rule system. Because of this, many consider decision trees to be one of, if not the simplest techiques to making AI (\cite{millington2019ai}, p.295; \cite{tozour2002evolution}, p.7).

FSMs, or Finite State Machines, are the most common approach to game AI (\cite{millington2019ai}, p309) due to the balance between their ease of understanding and the efficacy of their output. Jeff Orkin (\citeyear{orkin2006three}, p.1), a programmer who worked on F.E.A.R (\cite{FEAR}), said "If the audience of the Game Developers Conference were to be polled on the most common A.I techniques applied to games, one of the top answers would be Finite State Machines". FSMs consist of a directed graph where each node represents a state and the edges represent the transitions between them (\cite{tozour2002evolution}, p.6). What the states represent depend on the game, but they usually represent an expected behaviour of the character. A character can only be in one state at time and the state determines how they act at any given moment as well as the conditions necessary to switch to a different state (\cite{diller2004behavior}, p.3).

When using FSMs, controlling character behaviour can become quite straightforward as long as there is a clear idea about what is to be expected of a character and that these expectations of the character aren't too demanding. The process is still simple to implement like a decision tree due to the significant usage of rules that describe when the current state should switch to another (\cite{nareyek2004ai}, p.61), however, with a well designed FSM, the notion that a character's thought process is stateful gives off the impression that the character is indeed thinking. Given the correct game environment, this impression could appear to be good enough to compete with a neural network at a fraction of the time and resource cost despite not always being arriving at the optimal solution to the character's situation (\cite{sweetser2002current}).

Standard FSMs can only be in a single state at a time with no memory of the states it has previously been in, and the conditions that trigger the changing of state are described in the state itself (\cite{colledanchise2014performance}). With FSMs being such a good tool for the development of game AI, lots of implementations and additions have been discovered and used. One such addition has been the inclusion of fuzzy logic to make a FuSM (Fuzzy State Machine) (\cite{sweetser2002current}). The use of fuzzy logic involves replacing traditional boolean logic with real-numbers to allow a variable to represent something between $true$ and $false$ (\cite{tozour2002evolution}, p.7). With FuSMs, a character can partially be a member of multiple states at once - an enemy could be looking for a health pack while also fleeing from a player without there being a standalone state combining the two. This changes how transitions are implemented, as they are no longer instant or absolute. Instead, a state transition becomes an exchange of membership, where the FuSM's membership to a state increases while others decrease.

FuSMs are an improvement over FSMs because it allows you to combine and reuse states to have many variations that combine behaviour and rules of other states, however, this still means that whenever a new behaviour needs to be added to a character the programmer then needs to create a new state and the conditions of which this state integrates and transitions into other states. As states get added, these techniques becomes cumbersome to maintain (\cite{sweetser2002current}, p.2; \cite{lim2010evolving}, p.3). There's no easy way to combine the tests inside of FSMs, and even though FuSMs allow an AI to be a part of multiple states, selecting the conditions for a state transition is still very much a process that must be done by hand (\cite{millington2019ai}, p.313). 

The need for more flexibility in game AI has lead to the creation adaptation of modular algorithms such as behaviour trees (\cite{lim2010evolving}, p.1). Like decision trees, the recursive structure of a behaviour tree is simple to understand and implement while also being high level, allowing for more sophisticated AI to be created in a modular fashion through the use of subtrees (\cite{shoulson2011parameterizing}, p.144). A behaviour tree's nodes come in different types, but each type performs an action or check and then proceeds to succeed or fail (\cite{lim2010evolving}, p.4). It is these types that make the AI process at a higher level than standard decision trees. A selector node executes each child until one succeeds, in which case it itself will succed or otherwise fail. A sequence node does the opposite in the sense that it executes each child until one fails and will only succeed if every child also succeeds. A decorator node can only own and execute one child node and can do anything from repeat execution of the child or invert the child's returned status. When these node types are combined with leaf nodes that perform checks and actions to build trees, and then combined again to make trees containing subtrees, the simplicity and elegance of this technique certainly demonstrates why behaviour trees are getting attention (\cite{shoulson2011parameterizing}, p.144).

\subsubsection{AI and pathfinding}

One common requirement for game AI is for the characters to be able to traverse the areas of the game in a way which meets the player's expectations logically and efficiently - a task known as pathfinding. Regardless of what an AI decides to do, a pathfinding mechanic needs to be in place to allow the AI to navigate to where it needs to go, maneuvering around obstacles while still taking a sensible route (\cite{graham2003pathfinding}, p.60). For most games, the algorithm of choice is A* as it is the de-facto standard pathfinding algorithm (\cite{millington2019ai}, p.197; \cite{botea2004near}, p.2; \cite{nareyek2004ai}, p.64; \cite{leigh2007using}, p.73).

The A* algorithm analyses the game's map and generates a path from one location to another while minimising a $cost$ value - this value can represent anything but usually it represents the time or distance to travel along a given route (\cite{yap2002grid}, p.44). This means that the pathfinding algorithm itself doesn't decide where to go, only how to get there and the manner in which it does so. When asked to calculate a path, a pathfinding algorithm is provided a graph of nodes to determine which nodes can be reached from which (\cite{nareyek2004ai}, p.61). The algorithm isn't concerned with the what the data represents or in what form it is given, whether it is two-dimensional or three-dimensional, what the $cost$ is of travelling from one node to another, as long as it is equipped with the right functionality to digest this information (\cite{millington2019ai}, p.277; \cite{graham2003pathfinding}, p.60).

With the pathfinding process taking place after the decision has been made, the opportunity to involve the data gathered from pathfinding algorithm is missed. Often, the AI will decide to approach the nearest object, but obstacles in the way mean that the cost of navigating to the destination is greater than some alternative. While implementing the algorithm isn't difficult, ensuring the AI generates a path to the correct destination is difficult to do well (\cite{forbus2002qualitative}). Perhaps on the way to the destination, the character has to also navigate past traps or other hazards where it will need to decide whether to avoid or pass through - decisions that A* isn't fully equipped to deal with on it's own. If the AI wanted to factor in these hazards and real cost values, it would have to perform a more advanced check on where to travel too, maybe even using the pathfinding algorithm multiple times to definitely make sure that it wants to take the generated path, potentially ruining the game's performance.

Pathfinding algorithms are actually general purpose search algorithms applied to a spacial context (\cite{orkin2006three}, p.6; \cite{yap2002grid}, p.46). There is no such restriction that these algorithms should be restricted to pathfinding when in a games context. \citeauthor{millington2019ai} (\citeyear{millington2019ai}, p.197) said that "pathfinding can also be placed in the driving seat, making decisions about where to move as well as how to get there". With search algorithms having the flexibility of being able to traverse graphs of nodes representing any kind of data, it's no stretch to imagine the A* search algorithm being applied to a graph containing the same tests and actions found in decision and behaviour trees in order to generate a 'path' of actions rather than a path of spacial data (\cite{higgins2002generic}, p.114).

In this paper, the mechanisms of the A* search algorithm are examined and re-engineered, through the substitution of input and output types, to investigate the modularity and adaptability of an AI made in this way. The aim of using this approach is to bring decision-making and pathfinding closer together and therefore simplifying the overarching process of perceiving, deciding and interacting in the game world.

\subsection{Literature Review (11-12 pages)}

A solution is an action sequence, so search algorithms work by considering various possible action sequences (Artificial Intelligence: A modern approach). These pathfinding algorithms can search for a solution for traveling from A to B, but could potentially do more with the redefinition of what an action is. In theory, you could apply 'best first' to game interactions in a scenario.

Normally, pathfinding takes a backseat when it comes to decision making and just generates the requested path. However, since pathfinding algorithms are just search algorithms being applied to graphs, there's no restriction that these nodes and edges have to correspond to locations and distances.

Dijkstra's algorithm is a simple pathfinding algorithm that finds the shortest route to every node in the graph. It's an uninformed algorithm.

AStar is the defacto algorithm for pathfinding. Its actually a family of algorithms where the heuristic dictates how it functions. AStar with no heuristic is dijkstras, and could also be used to become a best-first, breadth first and depth-first.

Changing how A* evaluates actions and applies a heuristic will allow it to operate differently. A good heuristic will allow the algorithm to discard 'bad moves' (Depth-first iterative-deepening: an optimal admissable tree search).

A* becomes inefficient on bigger maps and lots of techniques have been created to adjust to these problems. Having lots of edges per node could make A* very inefficient.

This paper will investigate the effects of different cost and heuristic functions when changing the types involved with A* to see how agents perform.

\subsection{Methods and Methodologies}

\section {Design, Development and Evaluation}

\section{Design (14-15 pages when combined with development)}

\subsection {Development (14-15 pages when combined with design)}

\subsection {Results and Evaluation (11-12 pages including critical review)}

\section {Conclusions}

\subsection {Conclusions and Critical Review}

\printbibliography
\end{document}
