% # SEARCHES:

% ## AI Decision making in games:

% Call for AI research in RTS games (115 cites, not many references)
% https://www.aaai.org/Papers/Workshops/2004/WS-04-04/WS04-04-028.pdf
% "Increased playing strength can be converted into higher entertainment value by adapting to the player's performance level to keep games challenging" - p2
% "Agents cannot afford to think at the game action level. Instead, abstractions of the world state have to be foudn that allow programs to conduct forward searches in abstract spaces and translate found solutions back into the original state space" - p2
% "AI systems can be confused by simple maneuvers like flanking attacks and diversions" - p2
% "Understanding the importance of static terrain features like choke points and dynamic spatial properties such as visibility and enemy influence is crucial for generating successful plans" - p2
% "Another important aspect is the temporal relationship of actions" - p2
@inproceedings{buro2004call,
  title={Call for AI research in RTS games},
  author={Buro, Michael},
  booktitle={Proceedings of the AAAI-04 Workshop on Challenges in Game AI},
  pages={139--142},
  year={2004},
  organization={AAAI press}
}

% Current AI in games: A review (115 cites, mostly web articles)
% https://eprints.qut.edu.au/45741/1/AJIIPS_paper.pdf
% "The most prevalent techniques include finite state machines, scripting, agents and flocking. These techniques are well established, simple and have been successfully employed by game developers for a number of years" - p1
% "The use of fuzzy logic and fuzzy state machines as an alternative to finite state machines is starting to become widely accepted and commonplace" - p1
% "Finite state machines are used more frequently in computer games than any other AI technique. This is because they are simple to program, easy to understand and debug, and general enough to be used for any problem" - p2 (UNFOUND CITATION: "Implementing a state machine language")
% "The idea of an FSM is to divide a game object's behaviour into logical states so that the object has one state for each different type of behaviour it exhibits" - p2 (UNFOUND CITATION: "Desigining a general robust AI engine")
% "An FSM may not always provide the optimal solution, but it generally provides a simple solution that works. Furthermore, a game object that uses an FSM can use other techniques such as neural networks or fuzzy logic" - p2 (UNFOUND CITATION: "Desigining a general robust AI engine")
% "FSMs in games tend to include states within states, multiple state variables, randomness in state transitions and code executing every game tick" - p2 (UNFOUND CITATION: "Implementing a state machine language")
% "Game FSMs that are not well planned and structured can grow out-of-hand quickly and become very challenging to maintain." - p2
% "[FSMs can be used to] simulate the emotion of a non-player character" - p2 (UNFOUND CITATION "Game programming gems")
% "Important decisions that need to be made when designing an agent is the architecture and whether the agent is to be ractive, goal-directed or some combination of the two" - p2
@article{sweetser2002current,
  title={Current AI in games: A review},
  author={Sweetser, Penelope and Wiles, Janet},
  journal={Australian Journal of Intelligent Information Processing Systems},
  volume={8},
  number={1},
  pages={24--42},
  year={2002},
  publisher={ANU}
}

% AI in computer games (187 cites, Book)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.7072&rep=rep1&type=pdf
% "AI is very dependent on concrete details of the game environment, which is the main reason why it's often added as one of the last subsystems" - p59
% "Customers value great AI" - p60
% "Market mechanisms will make it very difficult for AI to receive equal ranking with features such as graphics and physics" - p60
% "A game using probabilistic networks to predict the player's next move in order to precompute graphics may be on a high AI level" - p60
% "The goal in game AI is not to compute the most optimal behaviour for winning against the player. Instead, the outcome should be as believable and fun as possible" -p60
% "Given the highly limited computational resources, a sophisticated movement is a really hard thing to do!" - p61
% "The so-called A* algorithm is the most common basic ingredient for computing a long-distance route for an NPC" - p61
% "The waypoints with their connections span a net over the map, defining which regions / points can be directly reached from other regions / points. Given a starting point and a destination, the A* algorithm tries to find the shortest path along the waypoint connections." - p61
% "The algorithm uses an estimation component, which has to provide an estimate for the distance between a point and the destination point. Thereby, the algorithm can focus its expansion of a possible path on the most promising connections." - p61
% "FSMs (finate state machines) describe under which events/conditions a current state is to be replaced by another" - p61
% "The game has no general FSM interpreter, but the FSMs are realized by scripts and simple if-then statements" - p61
% "Decision trees conceptually are even slightly simpler than FSMs and represent branching structures that are often used to make high-level strategic decisions" - 62
% "The nodes in the tree are test conditions, which lead to different sub-trees. A final leaf node contains a resulting decision. Similar to FSMs, decision trees are conceptual tools and can be realized by simple if-then statements" - p62
% "Game AI spans a large array of tasks, and it is not easy to generalize the various approaches. They are most often highly tailored to the specific games and situations" - p62
% "AI approaches from academia, such as genetic algorithms or neural networks, are hardly ever used in game development. Such approaches are generally believed to require too many resources for development, tuning and testing. The general approaches must be heavily modified and specialized for a specific game to get anything acceptable" - p64
% "A* is the most successful technique that AI research has come up with - and nearly the only one applied in computer games" - p64
@article{nareyek2004ai,
  title={AI in computer games},
  author={Nareyek, Alexander},
  journal={Queue},
  volume={1},
  number={10},
  pages={58},
  year={2004},
  publisher={ACM}
}

% ## Pathfinding algorithms for decision making:

% Implementing reccomendation algorithms for decision making processes (5 cites)
% NOTE: While this paper features elements used in this project, not much of it is applicable to a games context, even if it is using pathfinding in a different way.
% http://revistaie.ase.ro/content/63/08%20-%20Stanciu,%20Petrusel.pdf
% "We can argue that the decision making process can be look at as at a sequence of actions performed by the decision maker." - p87
% "We argue that existing high-level approaches to decision process modelign cannot precisely show why some decision makers succeed where others fail and it also cannot enable the transfer of knoweldge from one individual to another." - p87
@article{stanciu2012implementing,
  title={Implementing Recommendation Algorithms for Decision Making Processes.},
  author={Stanciu, Paula-Ligia and PETRU{\c{S}}EL, R{\u{a}}zvan},
  journal={Informatica Economica},
  volume={16},
  number={3},
  year={2012}
}

% Pathfinding in computer games (69 cites)
% https://arrow.dit.ie/cgi/viewcontent.cgi?article=1063&context=itbj
% "Pathfinding strategies have the responsibility of finding a path from any coordinate in the game world to another" - p57
% "Conceptually, a graph G is composed of two sets, and can be written as G = (V,E) where: V- Vertices: A set of discrete points in n-space, but this usually corresponds to a 3D map and E- Edges : A set of connections between the vertices, which can be either directed or not" - p59/60
% "Pathfinding algorithms also generally need to know about the properties of these elements. For example, the length, travel-time or general cost of every edge needs to be known" - p60
% "It is of no use to develop complex systems for high-level decision making if an agent cannot find its way around a set of obstacles to implement that decision." - p60
% "A pathfinder will define a path through a virtual world to solve a given set of constraints" - p60
% "In most cases it is desirable to have agents that finds optimal pathways as following sub-optimal pathways may be perceived as a lack of intelligence by a human player" - p63
% "In addition to holding the map location each node has three other attirbutes. These are fitness, goal and heuristic commonly known as f, g and h respectively." -p64
% "g is the cost of getting from the start node to the current node i.e. the sum of all the values in the path between the start and the current node" - p64
% "h stands for heuristic which is an estimated cost from the current node to the goaln ode (usually the straight line distance from this node to the goal)" - p64
% "f is the sum of g and h and is the best estimate of the cost of the path going through the current node. In essence the lower the value of f the more efficient the path" - p64
% "The purpose of f, g,  and h  is to quantify how promising a path is up to the present node. Additionally A* maintains two lists, an Open and a Closed list. The Open list contains all the nodes in the map that have not been fully explored yet, whereas the Closed list consists of all the nodes that have been fully explored." -p64
% [The actual A* algorithm is laid out] - p65
% "A* requires a large amount of CPU resources, if there are many nodes to search through as isthe case  in large maps which are  becoming popular in the newer  games.  In sequentialprograms this may cause a slight delay in the game. This delay is compounded if A* is searching for paths for multiple AI agents and/or when the agent has to move from one side of the map to the other. This drain on CPU resources may cause the game to freeze until the optimal path is found" - p67/68
% "A key issue constraining the advancement of the games industry is its over reliance on A* forpathfinding." - p68
@article{graham2003pathfinding,
  title={Pathfinding in computer games},
  author={Graham, Ross and McCabe, Hugh and Sheridan, Stephen},
  journal={The ITB Journal},
  volume={4},
  number={2},
  pages={6},
  year={2003}
}

% ## Pathfinding algorithms:

% Using a genetic algorithm to explore A*-like pathfinding algorithms (45 cites)
% https://www.cse.unr.edu/~sushil/class/gas/papers/Using%20a%20Genetic%20Algorithm%20to%20Explore%20A_-like%20Pathfinding%20Algorithms.pdf
% "Pathfinding algorithms are a subset of net search algorithms" - p75 (UNFOUND CITATION: Artificial Intelligence 3rd ed, P.H. Winston)
% "Pathfinding is often used in the context of games where nets represent the game map" - p72
% "A* is the de-facto pathfinding algorithm that, under the right conditions, guarantees to find a path with the lowest possible traversal cost. A* and other pathfinding algorithms work on a net." - p73
% "The guarantee of lowest cost paths only applies if the remaining estimate to the goal isan underestimate." - p73
% "The performance of A* relies heavily upon the estimate of remaining distance to the goal, called a heuristic. For A* to find the shortest path, the heuristic must underestimate the remaining distance." - p73
@inproceedings{leigh2007using,
  title={Using a genetic algorithm to explore A*-like pathfinding algorithms},
  author={Leigh, Ryan and Louis, Sushil J and Miles, Chris},
  booktitle={2007 IEEE Symposium on Computational Intelligence and Games},
  pages={72--79},
  year={2007},
  organization={IEEE}
}

% Grid-based path finding (141 cites)
% https://svn.sable.mcgill.ca/sable/courses/COMP763/oldpapers/yap-02-grid-based.pdf
% "In the past, better computer graphics have been the major technological sales feature of games." - p44
% "Path-finding is an important problem for many applications, including transportation routing, robot planning, military simulations and computer games" - p44
% "Path-finding involves analyzing a map to find the “best” cost of traveling from one point to another. Best can be a multi-valued function and use such criteria as the shortest path, least-cost path, safest path, etc. For many computer games this is an expensive calculation, made more difficult by the limited percentage of cycles that are devoted to AI processing." -44
% "Typically, a grid is superimposed over a region, and a graph search is used to find the best path. Most game programs conduct path-finding on a (rectangular) tile grid. Each tile has a positive weight that is associated with the cost to travel into that tile" - p44
% "The path-finding algorithm usually used is A*" - p44
% "A few games use IDA* (Iterative Deepening A*), which avoids A*s memory overhead usually at the cost of a slower search." - p44
% "Real-time constraitns limit the resources - both time and space - that can be used for path-finding." - p45
% "The demands for realism in games will always result in more detailed domain terrains, resulting in a finer grid and a larger search space." - p45
% "A* is the classic artificial intelligence optimization search algorithm. It uses a best-first search strategy, exploring the most likely candidate while eliminating provably inferior solutions." - p46
% "Its effectiveness is based on having a good heuristicestimator, H, on the remaining distance from the current state to a goal state." - p46
% "Since IDA* iterates and repeatedly explores paths, this may result in a horribly inefficient search." - p46
@inproceedings{yap2002grid,
  title={Grid-based path-finding},
  author={Yap, Peter},
  booktitle={Conference of the Canadian Society for Computational Studies of Intelligence},
  pages={44--55},
  year={2002},
  organization={Springer}
}

% A*-based pathfinding in modern computer games (153 cites)
% https://pdfs.semanticscholar.org/9ee1/5267cfce524c1e963534070aa7a192ae1f9c.pdf
% "Games like role-playing  games and  real-time  strategy  games often have characters sent on missions from their current location to a predetermined or player determined destination." - p125
% "A* is a generic search algorithm that can be used to find solutions for many problems, pathfinding just being one of them." - p125
% "Reducing the search space may significantly speed up A*." - p126
% "Finding the most appropriate data structure to represent the search space for the game world is absolutely critical to achieving realistic-looking movement and acceptable pathfinding performance." - p126
% "Hierarchical pathfinding is an extremely powerful technique that speeds up the pathfinding process. The complexity of the problem can be reduced by breaking up the world hierarchically." - p126
% "NavMesh is another popualr technique for AI pathfinding in 3D worlds. A NavMesh is a set of convex polygons that describe the 'walkable' surface of a 3D environment." - p126
% "The secret to the success of A* is that it extends Dijkstra's algorithm by introducing heuristic approach" - p126
% "A* algorithm improves the computational efficiency significantly by introducing a heuristic approach. Using a heuristic approach means, rather than an exhaustive expansion, only the states that look like better options are examined." - p127
% "A good heuristic function which can accurately estimate the cost may make the algorithm much quicker. On the other hand, using a heuristic that overestimates the true cost a little usually results in a faster search with a reasonable path." - p127 (UNFOUND CITATION, Game programming gems)
% "A* algorithm requires a huge amount of memory to track the progress of each search especially when searching on large and complex environments." - p127
% "Another alternative to reduce space requirements in A* is to compute the whole path in small pieces. This is the core concept behind IDA*" - p128
% "A priority queue is the best way to maintain an OPEN list." - p128
@article{cui2011based,
  title={A*-based pathfinding in modern computer games},
  author={Cui, Xiao and Shi, Hao},
  journal={International Journal of Computer Science and Network Security},
  volume={11},
  number={1},
  pages={125--130},
  year={2011},
  publisher={International Journal of Computer Science and Network Security (IJCSNS)}
}

% Partial pathfinding using map abstraction and refinement (164 cites)
% http://new.aaai.org/Papers/AAAI/2005/AAAI05-221.pdf
% NOTE: NO SUITABLE QUOTES FOUND
@inproceedings{sturtevant2005partial,
  title={Partial pathfinding using map abstraction and refinement},
  author={Sturtevant, Nathan and Buro, Michael},
  booktitle={AAAI},
  volume={5},
  pages={1392--1397},
  year={2005}
}


% ## Behaviour Trees:

% Evolving Behaviour Trees for the Commercial Game DEFCON (107 cites)
% http://ccg.doc.gold.ac.uk/ccg_old/papers/lim_evogames10.pdf
% "Behaviour trees have been proposed as an impovement over FSMs for designing game AI. Their advantages over traditional AI approaches are being simple to design and implement, scalability when games get larger and more complex, and modularity to aid reusability and portability." - p1
% "The problem with FSMs is that as the AI-bot grows in complexity, the number of states and transitions between them grows exponentially with the size of the game, making it difficult to manage." - p3
% "Behaviour trees provide a simple, scalable and modular solution to embody complex AI behaviours. Each tree is goal-oriented, i.e. associated witha distinct, high-level goal which it attempts to achieve. These trees can be linked together with one another, allowing the implementation of complex behaviours by first defining smaller, sub-behaviours" - p3
% "They are classified into 2 types, actions, which execute methods on the game, and conditions,which query the state of the game. Secondly, composite constructs can be usedto group such primitive constructs to perform a higher-level function. the 3 main types of composites are sequences,selectors and decorators." - p3
% [Talks about sequences, selectors and decorators etc] - p4
@inproceedings{lim2010evolving,
  title={Evolving behaviour trees for the commercial game DEFCON},
  author={Lim, Chong-U and Baumgarten, Robin and Colton, Simon},
  booktitle={European Conference on the Applications of Evolutionary Computation},
  pages={100--110},
  year={2010},
  organization={Springer}
}

% ## Behavior Trees:

% Parameterizing behavior trees (76 cites)
% https://people.cs.umass.edu/~fmgarcia/Papers/Parameterizing%20Behavior%20Trees.pdf
% "Behavior trees are garnering attention in the computer gaming industry for use in designing the artificial intelligence logic for environmental agents" - p144
% "The paradigm enables sophisticated sequences of actions and contingencies to be represented as aconcise graphical structure following a set of very simple rules with equivalent representations as Communicating Se-quential Processes (CSPs)." - p144
% "One of the most appealing aspects of behavior trees is their simplicity." - p144
@inproceedings{shoulson2011parameterizing,
  title={Parameterizing behavior trees},
  author={Shoulson, Alexander and Garcia, Francisco M and Jones, Matthew and Mead, Robert and Badler, Norman I},
  booktitle={International Conference on Motion in Games},
  pages={144--155},
  year={2011},
  organization={Springer}
}

% Performance analysis of stochastic behavior trees (36 cites)
% http://www.csc.kth.se/~petter/Publications/ICRA14_cmo.pdf
% "In FSMs, the state transitions are encoded in the states themselves, and switching from one state to the other leaves no memory of where the transition was made from." - p1
% [How Behaviour trees work, including in depth descriptions of the different types of nodes] - p2
@inproceedings{colledanchise2014performance,
  title={Performance analysis of stochastic behavior trees},
  author={Colledanchise, Michele and Marzinotto, Alejandro and {\"O}gren, Petter},
  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3265--3272},
  year={2014},
  organization={IEEE}
}

% Building behavior trees from observations in real-time strategy games (16 cites)
% https://www.cs.auckland.ac.nz/research/gameai/publications/Robertson_Watson_INISTA15.pdf
% NOTE: While an interesting paper with plenty of references, I couldn't find anything particularly useful for this paper due to behaviour trees being less important when compared to pathfinding. May need revisiting.
@inproceedings{robertson2015building,
  title={Building behavior trees from observations in real-time strategy games},
  author={Robertson, Glen and Watson, Ian},
  booktitle={2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA)},
  pages={1--7},
  year={2015},
  organization={IEEE}
}

% Behavior modeling in commercial games (40 cites)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.487.3985&rep=rep1&type=pdf
% "Another relevant trend in the commercial gaming industry is the increase in content authoring by users." - p2
% "The sensory mechanisms by which game characters “see” and in some cases “hear” the world range in complexity from the extremely simple to the surprisingly sophisticated and complex." - p3
% "Environments are typically reduced to simplified representation used only for navigation." - p3
% "The most common representations for decision-making processes in game characters are finite-state machines (FSMs). Character behaviors are modeled as a finite set of states with transitions between them in the form of a directed graph. The character resides in only one state at a time, with transitions between states driven by the conditions and actions occurring in the game." - p3
% "In most cases FSMs, and rule-based approaches are represented in game-specific script or code, rather than within a general purpose implementation." - p4
% "Recently, a few games have developed character behaviors using goal-directed reasoning techniques. In this technique game characters have a set of goals and actions are chosen in order to best satisfy the most relevant goal or goals." - p4
@inproceedings{diller2004behavior,
  title={Behavior modeling in commercial games},
  author={Diller, David E and Ferguson, William and Leung, Alice M and Benyo, Brett and Foley, Dennis},
  booktitle={Proceedings of the 2004 Conference on Behavior Representation in Modeling and Simulation (BRIMS)},
  pages={17--20},
  year={2004}
}

% AI for Games (910 cites)
% http://www.matt-versaggi.com/mit_open_courseware/GameAI/ArtificialIntelligenceforGamesSecondEdition.pdf
% "Artificial intelligence is about making computers able to perform the thinking tasks that humans and animals are capable of" - p4
% "Some decisions may require movement AI to carry them out. A melee (hand-to-hand) attack action will require the character to get close to its victim" - p10
% "Creating good AI is all about matching the right behaviors to the right algorithms." - p19
% "A heuristic is a rule of thumb, an approximate solution that might work in many situations but is unlikely to work in all." - p23
% "First, we must have some kind of infrastructure in two categories: a general mechanism formanaging AI behaviors (deciding which behavior gets to run when, and so on) and a world-interfacing system for getting information into the AI. Every AI algorithm created needs to honor these mechanisms." - p32
% "All movement algorithms have this same basic form. They take geometric data about their own state and the state of the world, and they come up with a geometric output representing themovement they would like to make." - p40
% "But pathfinding can also be placed in the driving seat, making decisions about where to moveas well as how to get there." - p197
% "The vast majority of games use pathfinding solutions based on an algorithm called A*." - p197
% "It doesn’t seem to make sense to have negative costs. [..] Mathematical graph theory does allow negative weights, however, and they have direct applications in some practical problems. These problems are entirely outside of normal game development" - p202
% "The principle problem with Dijkstra is that it searches the entire graph indiscriminately for the shortest possible route. This is useful if we’re trying to find the shortest path to every possible node (the problem that Dijkstra was designed for), but wasteful for point-to-point pathfinding." - p214
% "Pathfinding in games is synonymous with the A* algorithm. A* is simple to implement, is very efficient, and has lots of scope for optimization" - p215
% "A* implementations completely rely on the fact that they can theoretically produce non-optimal results. Fortunately, this can be controlled using the heuristic function. Depending onthe choice of heuristic function, we can guarantee optimal results, or we can deliberately allow sub-optimal results to give us faster execution." - p219
% [A* Pseudo code] - p220
% "The biggest factor in determining the performance of A* is the performance of its keydata structures: the pathfinding list, the graph, and the heuristic." - p228
% "If the heuristic underestimates in all possible cases, then the result that A* produces will be the best path possible." - p231
% "If the heuristic is too high, so that it overestimates the actual path length, A* may not return thebest path. A* will tend to generate a path with fewer nodes in it, even if the connections betweennodes are more costly." - p232
% "The only surefire way to get a decent heuristic is to visualize the fill of your algorithm." - p236
% "A* with a zero heuristic is the pathfinding version of Dijkstra." - p237
% "Often, the cost function is a blend of many different concerns, and there can be different cost functions for different characters in a game. A reconnaissance squad, for example,may be interested in visibility and speed. A heavy artillery weapon would be more interested in terrain difficulty. This is called tactical pathfinding" - p251
% "In many applications there may be more than one possible node in the graph that is a goal." - p272
% "Rather than checking if a node is the goal, we need to check if the node is a goal. This has implications for the design of the heuristic: the heuristic needs to accurately report the distanceto the nearest goal. To do that it needs to understand which goal will eventually be chosen." - p272
% "It is rare for game AI to use multiple goals at a great distance from one another. Usually, some kind of decision making process decides which alarm point to go to, and the pathfinding simply finds a route." - p272
% "The pathfinding system doesn’t understand what its graph represents. Itis simply trying to find the best route in terms of the graph" - p277
% "Decision trees are fast, easily implemented, and simple to understand. They are the simplest decision making technique" - p295
% "State machines are the technique most often used for this kind of decision making and, along with scripting, make up the vast majority of decision making systems used incurrent games." - p309
% "In a state machine, only transitions from the current state are considered, so notevery action can be reached." - p310
% "State machines don’t provide a simple way of combining these tests together to make more complex queries. If we need to transition based on the condition that the enemy is far away AND health is low, then we need some way of combining triggers together." - p313
% "We can combine the two approaches by replacing transitions from a state with a decision tree. The leaves of the tree, rather than being actions as before, are transitions to new states." - p331
% "[Behavior trees] strength comesfrom their ability to interleave these concerns in a way that is easy to understand and easy for non-programmers to create. Despite their growing ubiquity, however, there are things that are difficult to do well in behavior trees, and they aren’t always a good solution for decision making." - p334
% [How behavior trees work] - p335
% "Behavior trees implement a very simple form of planning, sometimes called reactive planning. Selectors allow the character to try things, and fall back to other behaviors if they fail. This isn’t avery sophisticated form of planning: the only way characters can think ahead is if you manually add the correct conditions to their behavior tree. Nevertheless, even this rudimentary planningcan give a good boost to the believability of your characters." - p340
% "Although we want data to pass between behavior trees, we don’t want to break their elegantand consistent API. We certainly don’t want to pass data into tasks as parameters to their run method. This would mean that each task needs to know what arguments its child tasks take and how to find these data." - p361
% "The most sensible approach is to decouple the data that behaviors need from the tasks them-selves. We will do this by using an external data store for all the data that the behavior tree needs. We’ll call this data store a blackboard." - p361
% "This simple approach to communication is fine in the absence of a richer data-exchange mechanism but should probably not be used if you are going to give your behavior tree tasks access to a full blackboard" - p365
@book{millington2019ai,
  title={AI for Games},
  author={Millington, Ian},
  year={2019},
  publisher={CRC Press}
}

% Building human-level AI for Real-Time Strategy Games (87 cites)
% https://www.aaai.org/ocs/index.php/FSS/FSS11/paper/viewFile/4209/4567
% "A second approach is to develop an abstraction of the state space and use it for reasoning about goals. This approach is also problematic, because different types of abstractions are necessary for the different tasks that need to be performed." - p329
@inproceedings{weber2011building,
  title={Building human-level ai for real-time strategy games},
  author={Weber, Ben George and Mateas, Michael and Jhala, Arnav},
  booktitle={2011 AAAI Fall Symposium Series},
  year={2011}
}

% ## Decision Trees:
% NOTE: Upon further inspection, decision trees require nothing more than a simple mention as a possible route for AI. As such, a lot of papers will not be read unless needed.

% Simplifying Decision Trees (2442 cites)
% http://www.bitsavers.org/pdf/mit/ai/aim/AIM-930.pdf
@article{quinlan14simplifying,
  title={Simplifying Decision Trees},
  author={Quinlan, JR},
  journal={contract},
  volume={14},
  number={85-K},
  pages={0124}
}

% Induction of decision trees (21280 cites)
% https://link.springer.com/content/pdf/10.1007/BF00116251.pdf
% "The basis is a universe of objects that are described in terms of a collection of attributes. Each attribute measures some important feature of an object and will be limited here to taking a (usually small) set of discrete, mutually exclusive values." - p85
% "Each object in the universe belongs to one of a set of mutually exclusive classes" - p86
% "The other major ingredient is a training set of objects whose class is known. The induction task is to develop a classification rule that can determine the class of any object from its values of the attributes. The immediate question is whether or not the attributes provide sufficient information to do this." - p86
@article{quinlan1986induction,
  title={Induction of decision trees},
  author={Quinlan, J. Ross},
  journal={Machine learning},
  volume={1},
  number={1},
  pages={81--106},
  year={1986},
  publisher={Springer}
}


% Constructing Optimal Binary Decision Trees is NP-Complete (1012 cites)
% https://people.csail.mit.edu/rivest/HyafilRivest-ConstructingOptimalBinaryDecisionTreesIsNPComplete.pdf
@article{laurent1976constructing,
  title={Constructing optimal binary decision trees is NP-complete},
  author={Laurent, Hyafil and Rivest, Ronald L},
  journal={Information processing letters},
  volume={5},
  number={1},
  pages={15--17},
  year={1976}
}

% Incremental induction of decision trees (1012 cites)
% https://link.springer.com/content/pdf/10.1023/A:1022699900025.pdf
@article{utgoff1989incremental,
  title={Incremental induction of decision trees},
  author={Utgoff, Paul E},
  journal={Machine learning},
  volume={4},
  number={2},
  pages={161--186},
  year={1989},
  publisher={Springer}
}

% Quantum computation and decision trees (929 cites)
% https://arxiv.org/pdf/quant-ph/9706062.pdf
@article{farhi1998quantum,
  title={Quantum computation and decision trees},
  author={Farhi, Edward and Gutmann, Sam},
  journal={Physical Review A},
  volume={58},
  number={2},
  pages={915},
  year={1998},
  publisher={APS}
}

% Multivariate Decision Trees (556 cites)
% https://link.springer.com/content/pdf/10.1007/BF00994660.pdf
@article{brodley1995multivariate,
  title={Multivariate decision trees},
  author={Brodley, Carla E and Utgoff, Paul E},
  journal={Machine learning},
  volume={19},
  number={1},
  pages={45--77},
  year={1995},
  publisher={Springer}
}

% Decision Trees for Decision Making (385 cites)
% https://pdfs.semanticscholar.org/8b50/f12a4240b7306ca4d0ac9199d192ddc90031.pdf
@book{magee1964decision,
  title={Decision trees for decision making},
  author={Magee, John F},
  year={1964},
  publisher={Harvard Business Review}
}

% Simplifying decision trees: A survey (396 cites)
% https://pdfs.semanticscholar.org/a0e3/e28c7635e69a1418d09030fcbdc2ff49a517.pdf
@article{breslow1997simplifying,
  title={Simplifying decision trees: A survey},
  author={Breslow, Leonard A and Aha, David W},
  journal={The Knowledge Engineering Review},
  volume={12},
  number={1},
  pages={1--40},
  year={1997},
  publisher={Cambridge University Press}
}

% # META SOURCES

% A practical guide to building a complete game AI: Volume 1 (7 cites, INTERNET ARTICLE)
% http://homepage.ttu.edu.tw/jmchen/gameprog/slides/gameai.pdf
% "Game AI is about creating an environment and the appearance of thought from units. Game AI is behavioral, not scientific." - p1
@article{howland2000practical,
  title={A Practical Guide to Building a Complete Game AI: Volume I},
  author={Howland, Geoff},
  journal={Lupine Games. Dispon{\i}vel em http://www. lupinegames. com/articles/prac ai. html},
  year={2000}
}

% A formal basis for the heuristic determination of minimum cost paths (8916 cites)
% https://www.cs.auckland.ac.nz/compsci767s2c/projectReportExamples.d/astarNilsson.pdf
% "A* is an improved version of Dijkstra's shortest-path algorithm" - p101
% "The nodes in the open list are ranked according to the formula f(n) = g(n) + h(n) where g(n) is...." - p102
% "The algorithm maintains two lists: open and closed..." (it talks a lot about how A* works) - p102
% "It might be argued that the algorithms of Moore, Busacker and Saaty, and other equivalent algorithms (sometimes known as "water flow" or "amoeba" algorithms) are advantagous because they first encounter the goal by a path with a minimum number of steps. This argument merely reflects an imprecise formulation of the problem, since it implies that the number of steps, and not the cost of each step, is the quantity to be minimised." - p106
% "The algorithm A* is actually a family of algorithms; the choice of a particular function h selects a particular algorithm from the family. The function h can be used to tailor A* for particular applications." - p107
% "The selection of h, therefore, permits one to choose a desirable compromise between admissibility, heuristic effectiveness, and computational efficiency" - p107
@article{hart1968formal,
  title={A formal basis for the heuristic determination of minimum cost paths},
  author={Hart, Peter E and Nilsson, Nils J and Raphael, Bertram},
  journal={IEEE transactions on Systems Science and Cybernetics},
  volume={4},
  number={2},
  pages={100--107},
  year={1968},
  publisher={IEEE}
}

% A note on two problems with connexion with graphs (24356 cites, The original Dijkstra)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.7577&rep=rep1&type=pdf
% [How Dijkstra's algorithm works] - p270
@article{dijkstra1959note,
  title={A note on two problems in connexion with graphs},
  author={Dijkstra, Edsger W},
  journal={Numerische mathematik},
  volume={1},
  number={1},
  pages={269--271},
  year={1959},
  publisher={Springer}
}

% A* pathfinding for beginners (169 cites)
% http://csis.pace.edu/~benjamin/teaching/cs627/webfiles/Astar.pdf
% [How A* works] - p1-7
% [F = G + H] - p2
% "The method we use here is called the Manhattan method, where you calculate the total number of squares moved horizontally and vertically to reach the target square from the currentsquare, ignoring diagonal movement, and ignoring any obstacles that may be in the way." - p3
% "What if you have terrain that is walkable, but at a higher movement cost? Swamps, hills, stairs in a dungeon, etc. – these are all examples of terrain that is walkable, but at a higher cost than flat, open ground. Similarly, a road might have a lower movement cost than the surrounding terrain. This problem is easily handled by adding the terrain cost in when you are calculating the G cost of any given node.Simply add a bonus cost to such nodes. The A* pathfinding algorithm is already written to find the lowest cost path and should handle this easily." - p8
% "An interesting additional consideration is something the professionals call “influence mapping.” Just as with the variable terrain costs described above, you could create an additional point system and apply it to paths for AI purposes. [...] This would teach the computer to favor safer paths, and help it avoid dumb situations where it keeps sending troops through a particular path, just because it is shorter (but also more dangerous)." - p8
% "Dijkstra's is essentially the same as A*, exceptthere is no heuristic (H is always 0)." - p10
@article{lester2005pathfinding,
  title={A* pathfinding for beginners},
  author={Lester, Patrick},
  journal={online]. GameDev WebSite. http://www. gamedev. net/reference/articles/article2003. asp (Acesso em 08/02/2009)},
  year={2005}
}

% The new science of management decision (8035 cites)
% NOTE: This is a book that needs to be bought
@article{simon1960new,
  title={The new science of management decision.},
  author={Simon, Herbert A},
  year={1960},
  publisher={Harper \& Brothers}
}

% Artificial Intelligence: A modern approach (38072 cites)
% NOTE: This book can be found on SHU's library gateway.
% "A solution is an action sequence, so search algorithms work by considering various possible action sequences. The possible action sequences starting at the initial state form a search tree with the initial state at the root; the branches are actions and the nodes correspond to states in the state space of the problem." - p77
% "we need to consider taking various actions. We do this by expanding the current state; that is, applying each legal action to the current state, thereby generating a new set of states." - p77
% "Search algorithms require a data structure to keep track of the search tree that is being constructed. For each node n of the tree, we have a structure that contains four components: • n.STATE: the state in the state space to which the node corresponds; • n.PARENT: the node in the search tree that generated this node; • n.ACTION: the action that was applied to the parent to generate the node; • n.PATH-COST: the cost, traditionally denoted by g(n), of the path from the initial state to the node, as indicated by the parent pointers." - p80
% "We can evaluate an algorithm’s performance in four ways: • Completeness: Is the algorithm guaranteed to find a solution when there is one? • Optimality: Does the strategy find the optimal solution, as defined in section 1.1? • Time complexity: How long does it take to find a solution? • Space complexity: How much memory is needed to perform the search?" - p82
% "Complexity is expressed in terms of three quantities: b, the branching factor or maximum number of successors of any node; d, the depth of the shallowest goal node (i.e., the number of steps along the path from the root); and m, the maximum length of any path in the state space." - p82
% "In general, exponential-complexity search problems cannot be solved by uninformed methods for any but the smallest instances." - p85
% "The general approach we consider is called best-first search. Best-first search is an instance of the general TREE-SEARCH or GRAPH-SEARCH algorithm in which a node is selected for expansion based on an evaluation function, f(n). The evaluation function is construed as a cost estimate, so the node with the lowest evaluation is expanded first." - p94
% "The most widely known form of best-first search is called A∗ search (pronounced “A-star search”). It evaluates nodes by combining g(n), the cost to reach the node, and h(n), the cost to get from the node to the goal: f(n) = g(n) + h(n) ." - p95
% "A learning algorithm can be used to construct a function h(n) that can (with luck) predict solution costs for other states that arise during search." - p109
@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Malaysia; Pearson Education Limited,}
}

% Map based Strategies for Robot Navigation in Unknown Environments (57 cites)
% https://www.aaai.org/Papers/Symposia/Spring/1996/SS-96-04/SS96-04-017.pdf
% "The problem with this approach is strictly computational: replanning is an expensive operation. If the robot's prior map information is sparse or inaccurate, then too much time will be spent replanning in Step 2 for the approach to be viable. The D * algorithm (Dynamic A *) [Stentz, 94J was developed to solve this computational problem. D* produces an optimal traverse by using incremental graph theory techniques to dramatically reduce the time required to replan. For environments with a large number of states, D* is capable of replanning hundreds of times faster than straight-forward, brute-force replanning algorithms." - p110
@inproceedings{stentz1996map,
  title={Map-based strategies for robot navigation in unknown environments},
  author={Stentz, Anthony},
  booktitle={AAAI spring symposium on planning with incomplete information for robot problems},
  pages={110--116},
  year={1996}
}

% Depth-first iterative-deepening: an optimal admissable tree search (2077 cites)
% https://www.iis.sinica.edu.tw/~tshsu/tcg/2012/slides/slide3.pdf
% "No need to worry about a good cut-off depth as in DFS." - slide 22
% "Good for a tournament situation where each move needs to bemade in a limited amount of time." - slide 22
% "A heuristic search is a search algorithm that uses information about: The initial state, operators on finding the states adjacent to a state, a test function whether a goal is reached, and heuristics to pick the next state to explore." - slide 27
% "A “good” heuristic search algorithm: - States that are no  likely leading to the goals will not be explored further..A state is cut or pruned. States are explored in an order that are according to their likelihood of leading to the goals -> good move ordering."
% "[A*] consumes a lot of memory to record the set of visited nodes" - slide 30
% "IDA∗ does not need to use a priority queue as in the case ofA∗. IDA∗ is optimal in terms of solution cost, time, and space over the class of admissible best-first searches on a tree." - slide 36
% "Cost function is the knowledge used in searching." - slide 36
@article{korf1985depth,
  title={Depth-first iterative-deepening: An optimal admissible tree search},
  author={Korf, Richard E},
  journal={Artificial intelligence},
  volume={27},
  number={1},
  pages={97--109},
  year={1985},
  publisher={Elsevier}
}

% Fringe Search: Beating A* at Pathfinding on Game Maps (92 cites)
% NOTE: This paper is about efficiency of pathfinding algorithms. Will read another time.
% http://www.ru.is/faculty/yngvi/pdf/BjornssonEHS05.pdf
@article{bjornsson2005fringe,
  title={Fringe Search: Beating A* at Pathfinding on Game Maps.},
  author={Bj{\"o}rnsson, Yngvi and Enzenberger, Markus and Holte, Robert C and Schaeffer, Jonathan},
  journal={CIG},
  volume={5},
  pages={125--132},
  year={2005}
}

% Games get serious (46 cites)
% https://journals.sagepub.com/doi/full/10.2968/062004010
% NOTE: No useful citations other than references to the growth of the games industry with examples
@article{schollmeyer2006games,
  title={Games get serious},
  author={Schollmeyer, Josh},
  journal={Bulletin of the Atomic Scientists},
  volume={62},
  number={4},
  pages={34--39},
  year={2006},
  publisher={SAGE Publications Sage UK: London, England}
}

% How qualitative spatial reasoning can improve strategy game AIs (108 cites)
% https://www.aaai.org/Papers/Symposia/Spring/2001/SS-01-02/SS01-02-008.pdf
% NOTE: FIND CITATIONS FOR THE FOLLOWING:
% "Path-finding in computer games may be conceptually easy, but for many game domains it is difficult to do well"
@article{forbus2002qualitative,
  title={How qualitative spatial reasoning can improve strategy game AIs},
  author={Forbus, Kenneth D and Mahoney, James V and Dill, Kevin},
  journal={IEEE Intelligent Systems},
  volume={17},
  number={4},
  pages={25--30},
  year={2002},
  publisher={IEEE}
}

% Human-level AI's killer application: Interactive computer games (551 cites)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.384.9845&rep=rep1&type=pdf
% "Human-level AI can expand the types of experiences people have playing computer games by introducing synthetic intelligent characters with their own goals, knowledge, and capabilities. Human-level AI can also recreate the experience of playing with and against humans without a network connection." - p16
% "Our hypothesis is that populating these games with realistic, human-level characters will lead to fun, challenging games with great game play." - p16
% "Synthetic human-level characters are playing an increasingly important role in many genres of computer games and have the potential to lead to completely new genres." - p17
% "Thus, most, if not all, of the current techniques that are used for controlling game AIs (such as big Cfunctions or finite-state machines) will not scale up" - p17
% "These agents don’t necessarily have to be human level in their intelligence, as long as they have a façade of intelligence supported by great personality." - p17
% "Building  human-level  enemies  for  these games requires solving many general AI problems and integrating the solutions into coherent systems. The enemies must be autonomous. They must interact with complex dynamic environments, which requires reactive behavior, integrated  planning, and common sense reasoning. As they advance, they will also need models of high-level vision that have the same strengths and weaknesses as humans." - p22
% "There are many other applications of AI to building intelligent enemies. Because of the extended geography of the environment, they must navigate and use path planning, spatial reasoning, and temporal reasoning." - p22
@article{laird2001human,
  title={Human-level AI's killer application: Interactive computer games},
  author={Laird, John and VanLent, Michael},
  journal={AI magazine},
  volume={22},
  number={2},
  pages={15--15},
  year={2001}
}

% Heuristics: Intelligent search strategies for computer problem solving (4162 cites)
% NOTE: This book can be found on SHU's library gateway.
% "Heuristics are criteria, methods or principles for deciding which among several alternative courses of action promises to be the most effective in order to achieve some goal" - p3
@article{pearl1984heuristics,
  title={Heuristics: intelligent search strategies for computer problem solving},
  author={Pearl, Judea},
  year={1984},
  publisher={Addison-Wesley Pub. Co., Inc., Reading, MA}
}

% Near optimal hierarchical path-finding (505 cites)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.479.4675&rep=rep1&type=pdf
% "The industry standard is to use A* or iterative-deepening A*, IDA*. A* is generally faster, but IDA* uses less memory." - p2
% "Quadtrees have been proposed as a way of doing hierarchical map decomposition. This method partitions a map into square blocks of different izes so that a block contains either only walkable cells or only blocked cells. [..] An action in this abstracted framework is to travel between the centers of two adjacent blocks. Since the agent always go to the middle of a box, this method produces sub-optimal solutions" - p6
% "In Framed quadtrees, the border of a block is augmented with cells at the highest resolution. An action crosses a block between any two border cells. Since this representation permits many angles of direction, the solution quality improves significantly. On the other hand, framed quadtrees use more memory than quadtrees." - p6
% "The method adapts to dynamically changing environments. The hierarchy can be extended to several abstraction levels, making it scalable for large problem spaces. We tested our program using maps extracted from a real game, obtaining near-optimal solutions significantly faster than low-level A*." - p19
@article{botea2004near,
  title={Near optimal hierarchical path-finding},
  author={Botea, Adi and M{\"u}ller, Martin and Schaeffer, Jonathan},
  journal={Journal of game development},
  volume={1},
  number={1},
  pages={7--28},
  year={2004},
  publisher={Citeseer}
}

% Three states and a plan: the AI of FEAR (228 cites)
% http://alumni.media.mit.edu/~jorkin/gdc2006_orkin_jeff_fear.pdf
% "If the audience of the Game Developers Conference were to be polled on the most common A.I techniques applied to games, one of the top answers would be Finite State Machines (FSMs)" - p1
% "Let’s compare FSMs to planning.  An FSM tells an A.I.exactly how to behave in every situation.  A planning system tells the A.I. what his goals and actions are, and lets the A.I.decide how to sequence actions to satisfy goals.  FSMs are procedural, while planning is declarative.  " - p.3
% "This is basically what we did forF.E.A.R., but instead of planning ways to satisfy hunger, we were planning ways of eliminating threats.  We can satisfy the goal of eliminating a threat by firing a gun at the threat, but the gun needs to be loaded, or we can use a melee attack, but we have to move close enough." - p.6
% "The previous case study illustrates the first of three benefits of a planning system.  The first benefit is the ability to decouple goals and actions, to allow different types of characters to satisfy goals in different ways.  The second benefit of a planning system is facilitation of layering simple behaviors to produce complex observable behavior.  The third benefit is empowering characters with dynamic problem solving abilities." - p.7
% "With a planning system, we can give each character their own Action Set, and in this case only the policemen would have the action for catching their breath.  This unique behavior would not add any unneeded complexity to other characters." - p.8
% "We give the A.I. the ability to reposition when his current cover position is invalidated.  This simply requires adding the Ambush goal.  When an A.I.’s cover is compromised, he will try to hide at a node designated by designers as an Ambush node." - p.9
% "Earlier we said that if Alma has both the phone number and the recipe, either plan is valid to satisfy her hunger.If we assign a cost per action, we can force Alma to prefer one action over another.  For example we assign the OrderPizza action a cost of 2.0, and the BakePieaction a cost of 8.0.  If she cannot satisfy the preconditions of ordering pizza, she can fall back to baking a pie." - p.11
% "In the case of planning, the nodes are states of the world, and we are searching to find a path to the goal state.  The edges connecting different states of the world are the actions that lead the state of the world to change from one to another." - p.11
% "So, we use A* for both navigation and planning in F.E.A.R., and in each case we search through entirely different data structures.  However, there are situations where we use both. " - p.11
% "For instance, the Gotoaction can satisfy the Covergoal, allowing the A.I. to arrive at the desired cover node.  The Cover goal specifies which node to Goto in the array representing the goal world state." - p12
% "An A.I.trying to escape danger will run away if he can find a path to safety, or hunker down in place if he can’t find anywhere to go.  The run away action is preferable, but can only be used if the CheckProceduralPreconditions() function return true after searching for a safe path through the NavMesh." - p.12
% "We have a global coordinator in F.E.A.R. that periodically re-clusters A.I. into squads based on proximity.At any point in time, each of these squads may execute zero or one squad behaviors.Squad behaviors fall into two categories, simple and complex behaviors.Simple behaviors involve laying suppression fire, sending A.I. to different positions, or A.I. following each other.  Complex behaviors handle things that require more detailed analysis of the situation, like flanking, coordinated strikes, retreats, and calling for and integrating reinforcements." - p.13
%Dynamic situations emerge out of the interplay between the squad level decision making, and the individual A.I.’s decision making, and often create the illusion of more complex squad behavior than what actually exists!" - p.14
@inproceedings{orkin2006three,
  title={Three states and a plan: the AI of FEAR},
  author={Orkin, Jeff},
  booktitle={Game Developers Conference},
  volume={2006},
  pages={4},
  year={2006}
}

% Games market worth
% https://newzoo.com/key-numbers/
@report{Newzoo,
  title={2019 Global Games Market per device and segment},
  author={Newzoo},
  type={Market Report},
  year=2019,
  url={https://newzoo.com/key-numbers/},
  urldate={2019-11-30}
}

% Game development, harder than you think (212 cites)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.622.4481&rep=rep1&type=pdf
% "In early games, the simulations were simple and primitive. For a while we focused mainly on graphics" - p36
% "But now we are enter-ing a time when the portions of the simulation governing physics and AI can be more important to the end user’s quality of experience than the graphics. " - p36
@article{blow2004game,
  title={Game development: Harder than you think},
  author={Blow, Jonathan},
  journal={Queue},
  volume={1},
  number={10},
  pages={28},
  year={2004},
  publisher={ACM}
}

% Unity game engine
@software{Unity,
  author = {{Unity Technologies}},
  title = {Unity Engine},
  type = {Game Engine},
  year = 2005,
  version = {2019.2.14},
  url = {https://unity.com},
  urldate = {2019-11-30}
}

% Unreal game engine
@software{Unreal,
  author={{Epic Games}},
  title={Unreal Engine},
  type={Game Engine},
  year=1998,
  version={4.23.1},
  url={https://www.unrealengine.com/en-US/},
  urldate={2019-11-30}
}

% F.E.A.R game
@software{FEAR,
  author={{Monolith Productions}},
  title={{F.E.A.R}},
  type={Video Game},
  year=2005
}

% Applying Goal-Oriented Action Planning to Games
% http://alumni.media.mit.edu/~jorkin/GOAP_draft_AIWisdom2_2003.pdf
% " Goal-Oriented Action Planning (GOAP) is a decision-making architecture that takes the next step, and allows characters to decide not only what to do, but how to do it. " - p1
% "A goal is any condition that an agent wants to satisfy. " - p1
% "The plan is simply the name for a sequence of actions. A plan that satisfies a goal refers to the valid sequence of actions that will take a character from some starting state to some state that satisfies the goal." - p2
% "An action is a single, atomic step within a plan that makes a character do something." - p2
% "A GOAP system does not replace the need for a finite-state machine (FSM) [Fu03], but greatly simplifies the required FSM. A plan is a sequence of actions, where each action represents a state transition. By separating the state transition logic from the states themselves, the underlying FSM can be much simpler." - p2
% "A character generates a plan in real-time by supplying some goal to satisfy to a system called a planner. The planner searches the space of actions for a sequence that will take the character from his starting state to his goal state. This process is referred to as formulating a plan. " - p3
% " Characters in the game can exhibit more varied, complex, and interesting behaviors using GOAP. The code behind the behaviors is more structured, re-usable, and maintainable." - p4
% "GOAP offers a much more elegant structure that better accommodates change. The addition of design requirements is handled by adding actions, and preconditions to related actions. This is more intuitive, and touches less code than revisiting every goal." - p5
% "Furthermore, GOAP provides the guarantee of valid plans. Hand-coded embedded plans can contain mistakes." - p5
% "Though many game developers think of A* as a pathfinding algorithm, it is actually a general-purpose search algorithm. " - p6
% "The A* algorithm requires the calculation of the cost of a node, and the heuristic distance from a node to the goal. Nodes in the planner’s search represent states of the world, with edges representing actions between them. The cost of a node can be calculated as the sum of the costs of the actions that take the world to the state represented by the node. The cost of each action may vary, where lower cost actions are more preferable. The heuristic distance can be calculated as the sum of the unsatisfied properties of the goal state." - p7
% "A regressive search is more efficient and intuitive. " - p7
% "With each new game released, the bar is set higher for AI behavior. As expectations for the complexity of character behavior rises, we need to look toward more structured, formalized solutions to creating scalable, maintainable, and re-usable decision-making systems. Goal-oriented action planning is one such solution. By letting go of the reins and allowing games to formulate plans at runtime, we are handing over key decisions to those who are in the best position to make them; the characters themselves." - p11
@article{orkin2003applying,
  title={Applying goal-oriented action planning to games},
  author={Orkin, Jeff},
  journal={AI game programming wisdom},
  volume={2},
  pages={217--228},
  year={2003}
}

% AI Game programming wisdom (71 cites)
% "Finite-state machines are simple, rule-based systems in which a finite number of "states" are connected in  a directed  graph by "transitions" between  states. The finite-state machine occupies exactly one state at any moment." - 6
% "Production rule systems are essentially lists of "if-then" statements, with various conflict res- olution mechanisms available in  the event that more than  one rule is  satisfied simultaneously." - p6
% "Decision trees are similar to complex conditionals in "if-then" statements. DTs make a decision based on a set of inputs by starting at the root of the tree and, at each node, selecting a child  node based on the value of one input. - p6
% "Search methods are concerned with discovering a sequence of actions or states within a graph that satisfy some goal-either reaching a specified "goal state" or simply maximizing some value based on the reachable states." - p6
% "Planning systems and scheduling systems are an extension of search methods that emphasize the subproblem of finding the best (simplest) sequence of actions that one can perform to achieve a particular result over time, given an initial state of the world and a precise definition of the consequences of each possible action. " - p6
% "[Genetic algorithms] attempt to imi- - tate the process of evolution directly, performing selection and interbreeding with randomized crossover and  mutation operations on populations of programs, algorithms, or sets of parameters. " - p7
% "Neural networks are a class of machine learning techniques based on the archi- tecture of neural interconnections in animal brains and nervous systems. " - p7
% "Fuzzy logic uses real-valued numbers  to represent degrees of  membership  in  a number  of sets-as opposed to the Boolean (true or false) values of traditional logic. " -p7
% "Ironically, it is  the simplest techniques-finite-state machines, decision trees, and production  rule systems-that have most often proven their worth. Faced with  tight schedules and minimal resources, the game A1 community has  eagerly embraced rules-based systems as the easiest type of A1 to create, understand, and debug." - p7
% "Its surprisingly easy to develop an AI that will consistently trounce the player without breaking a sweat. This is  "intelligentn from that AI's per- spective, but it's not what our customers bought the game for." - p9
% We cannot develop great game AI without addressing all of the problems that each AI agent faces within the game." -  p11
% "For AI to reach its  full  potential,  game design must evolve beyond  its  all-too- common obsession with designer-controlled  narrative and linear gameplay. It's not about the story: it's about the gameplay. " - p13
@article{tozour2002evolution,
  title={The evolution of game AI},
  author={Tozour, Paul},
  journal={AI game programming wisdom},
  volume={1},
  pages={3--15},
  year={2002}
}

% The illusion of intelligence (85 cites)
% "Human players can be both predictable and unpredictable. In some cases, this  can  happen within  the same game. In other cases, a human player might be unpredictable across multiple game sessions, but pre- dictable within a single game. " - p17
% "You should strive to provide as many  surprises as you  can. Players will notice an A1 that performs an admirable job of playing the game, but they will talk about an A1 that surprises them." - p17
% "We  could  separate our game audience into two groups. First is  the player who just wants to win easily. The second group is  the player who wants to win half the time and lose half the time. They usually want the battle to appear nearly hopeless until the end when they turn the tide of battle and prove their superiority." - p18
@article{scott2002illusion,
  title={The illusion of intelligence},
  author={Scott, Bob},
  journal={AI game programming wisdom},
  volume={1},
  pages={16--20},
  year={2002}
}

% Generic A* pathfinding (32 cites)
% "A good path- finding engine can be used for many more purposes than just moving units around the world." - p114
% "Templates are essential to making the A* machine reusable and fast. Certainly, you can gain reusability by using base  classes and virtual functions, but this architecture achieves reusability and great speed by using templates. " - p117
% "Reuse that A*. Instead  of writing  a pathfinding  engine, write  a generic A* engine. This way it  can be  used for much more than just pathfinding. It would be a shame to not take advantage of the months or years of optimization work. " - p120
% "Templatize your engine. Use templates to get speed and reusability  Don't be intimidated by templates,  they are amazing tools. Check your compiler to see how it well it deals with templates." - p120
% "Customize goal classes. Use different types of goal classes. The goal classes should be extremely specific to the current task. " - p121
@article{higgins2002generic,
  title={Generic A* pathfinding},
  author={Higgins, Dan},
  journal={AI Game Programming Wisdom},
  pages={114--121},
  year={2002},
  publisher={Charles River Media, Inc., Massachusetts}
}

% Pathfinding design architecture (35 cites)
% "Quick paths are designed to get a unit moving. When a player gives a unit an order, he expects the unit  to respond  quickly rather than sit and think for a while. " - p123
@article{higgins2002pathfinding,
  title={Pathfinding design architecture},
  author={Higgins, Dan},
  journal={AI Game Programming Wisdom},
  pages={122--132},
  year={2002},
  publisher={Charles River Media, Inc., Massachusetts}
}

% An economic approach to goal directed reasoning
% "Sometimes,  a goal is too  complicated to address directly-the goal "win the game" is  a good example-and it is  necessary to decompose the goal into smaller sub- goals that are, ideally,  easier to  attempt. It is  most useful when  the  union of these subgoals completely describes the goal, but  that is  an unlikely case in  many games, because of unpredictability." - p403
% "An opportunity cost is what you must give up in order to perform an action. For exam- ple, in Chess, the opportunity cost of moving one of your pieces is  not being able to move any of your other pieces, An opportunity cost is  incurred whenever an action is performed that cannot be performed in parallel with all other actions; hence, oppor- tunity costs are linked to choice. " - p405
% "When implementing your pathfinding system,  allow for  your node weighting  to accept a dynamic utility heuristic that works in conjunction with your cost heuristic. Such a system can allow you to chain pathfinding subgoals so that, for example, you can take full advantage of changes in terrain desirability, you can  stage attacks from 
multiple locations, and you can create complex pathfinding plans that require multi- ple steps" - p410
@article{harmon2002economic,
  title={An economic approach to goal-directed reasoning in an RTS},
  author={Harmon, Vernon},
  journal={AI Game Programming Wisdom},
  pages={402--410},
  year={2002},
  publisher={Charles River Media, Inc., Massachusetts}
}

% An algorithm for finding best matches in logarithmic time (3330 cites)
@article{friedman1976algorithm,
  title={An algorithm for finding best matches in logarithmic time},
  author={Friedman, Jerome H and Bentley, Jon Louis and Finkel, Raphael Ari},
  journal={ACM Trans. Math. Software},
  volume={3},
  number={SLAC-PUB-1549-REV. 2},
  pages={209--226},
  year={1976}
}
